# PUF to IRS Variable Mapping

This document maps PUF (Public Use File) variables to corresponding values in IRS spreadsheets for 2015 (the PUF year) and 2022 (for comparison).

## Overview

This mapping documents the relationships between: - PUF microdata variables (2015) - IRS spreadsheet totals for 2015 - TMD (Tax Microdata) values for 2022 - IRS spreadsheet totals for 2022

The goal is to establish appropriate mappings for setting national targets based on IRS data.

Steps:

-   compare reported aggregates in IRS tables for 2015 to the documentation for 2015

```{r}
#| label: setup

GITROOT <- rprojroot::find_root(rprojroot::has_file(".git/index"))
QROOT <- fs::path(GITROOT, "tmd", "national_targets", "qmd")
source(fs::path(QROOT, "setup.R"))

pufpath <- fs::path(TMDINPUT, "puf_2015.csv")

# note - will load the functions that help with reading excel files
# also loads QROOT, DATADIR, and targfn

# format:
#   html:
#     code-fold: true

```

## Get ptargets and add target type info

Later, put in prepare.qmd

```{r}

# potential targets
ptargets1 <- readRDS(fs::path(DATADIR, "potential_targets_preliminary.rds"))
count(ptargets1, table, fname)
count(ptargets1, table)

ptargets2 <- ptargets1 |>
  mutate(
    subgroup = case_when(
      table == "tab11" ~ "all",
      table == "tab14" ~ "all",
      table == "tab12" ~ "marstat",
      table == "tab21" ~ "itemizers",
      .default = "ERROR"
    ),
    targtype = case_when(
      str_starts(vname, "nret") ~ # review this for other kinds of variables
        "number",
      .default = "amount"
    ),
    .after = datatype
  ) |>
  arrange(year, datatype, subgroup, targtype) |>
  mutate(targetid = row_number(), .before = 1)

```

```{r}
#| label: ptargets-info
#| output: true

glimpse(ptargets2)
skimr::skim_without_charts(ptargets2)

count(ptargets2, year, datatype, subgroup, targtype)

```


## Get data from PUF documentation

The following data is from the PUF documentation booklet. Tables were copied carefully into the Excel file used below and carefully supplemented. It is the most labor-intensive and error-prone part of the targets process.

Get weighted sums of numeric variables, from PUF 2015 documentation pages 46-50. The screenshot below shows what the table looks like. It includes:

-   SOI PUF 2015 variable name – e.g., first row is PUF variable E00100, Adjusted gross income

-   2015 Full SOI Individual Sample amount – this is the amount in the full (non-public-use) IRS sample (we do **not** have this data file). It is also, generally, the amount found in IRS public tables and what we should consider a control total for 2015.

-   2015 Public Use Sample amount - We generally can calculate this from the full 2015 PUF sample (as long as we include the four aggregate records).

Our detective job is to:

-   Pick an important PUF variable that we may want to target

-   Verify that it is what we think it is by summarizing the 2015 PUF and comparing to this table

-   Find its counterpart in 2015 published IRS tables so that we know which IRS table has detailed targeting information for that variable

-   Find its counterpart in 2022 published IRS tables so that we know which 2022 IRS table has detailed targeting information for that variable

![](images/paste-1.png)

```{r}

xlpath <- fs::path(DATADIR, targfn)
sheet <- "puf2015_wtdsums"
range <- "A3:E176"

mainvars <- readxl::read_excel(xlpath, sheet = sheet, range = range)

```

## Calculate PUF weighted sums, for comparison

```{r}
#| label: get-raw-puf

puf <- vroom::vroom(pufpath)

pufsums <- puf |>
  select(RECID, S006, any_of(mainvars$puf_name)) |>
  summarise(across(-c(RECID, S006), \(x) sum(x * S006 / 100))) |>
  pivot_longer(cols = everything(), names_to = "puf_name", values_to = "pufsum")

```

## Examine and adjust full-sample values for key PUF variables

### Compare PUF weighted sums to those reported in PUF documentation

```{r}

tabdata <- mainvars |>
  left_join(
    pufsums |> mutate(pufsumk = pufsum / 1000) |> select(puf_name, pufsumk),
    by = join_by(puf_name)
  ) |>
  mutate(diff = pufsumk - PUF_2015, pdiff = diff / PUF_2015) |>
  select(-form_location_2015) |>
  arrange(desc(abs(diff))) |>
  mutate(row = row_number(), .before = puf_name)

tol <- 0.0001
tol_txt <- scales::label_percent(accuracy = 0.01)(tol)
nvars <- nrow(tabdata)

```

The table below compares weighted sums for variables included in puf 2015 to what the PUF documentation says to expect, where the calculated sum is different from the sum reported in the documentation by more than `{r} tol_txt`. It also shows the amount in the full SOI sample, which is the amount we would expect to find in IRS spreadsheets.

Almost all `{r} nvars` PUF variables compared are within `{r} tol_txt`. Of those that differ by more, all but one differ by approximately a factor of 10. This suggests that for these variables the IRS accidentally either (1) truncated the reported amounts by one digit, making the expected amount too low, or (2) increased the amounts on the PUF by a factor of 10, making the amounts in the data too large by a factor of 10.

```{r}

tabdata |>
  filter(abs(pdiff) > tol) |>
  gt() |>
  tab_header(
    paste0(
      "PUF 2015 weighted sums that differ from PUF 2015 documentation by more than ",
      tol_txt,
      ". Amounts in $ thousands"
    ),
    subtitle = paste0("Out of ", nvars, " variables")
  ) |>
  tab_spanner(
    "PUF 2015 documentation",
    columns = c(SOI_sample_2015, PUF_2015)
  ) |>
  cols_label(
    SOI_sample_2015 = "2015 Full SOI sample (What we should expect to find in IRS spreadsheets)",
    PUF_2015 = "2015 Public Use sample (What we should expect for calculated sum)",
    pufsumk = "Calculated weighted sum",
    diff = "Calculated minus expected",
    pdiff = "% difference from expected"
  ) |>
  fmt_number(
    columns = c(SOI_sample_2015, PUF_2015, pufsumk, pdiff),
    decimals = 0
  ) |>
  fmt_percent(columns = pdiff, decimals = 1)

```

Note that the reported full sample amounts are also off by a factor of 10. The next two tables show values in IRS tables for state and local tax deductions and for deductible interest. This makes clear that the reported full sample amounts for these variables in the PUF documentation are wrong.

Thus, we adjust the full sample amounts for these variables by a factor of 10 so that we can compare them to amounts found in IRS tables.

![](images/paste-4.png)

![](images/paste-3.png)

### Correct the adjusted full-sample amounts taken from the PUF documentation

```{r}

# adjust the full-sample numbers

compdata1 <- tabdata |>
  select(row, puf_name, description, SOI_sample_2015, PUF_2015, pufsumk) |>
  mutate(
    adjust = abs(pufsumk) / abs(PUF_2015) > 9,
    mult = ifelse(is.na(adjust) | adjust, 10, 1),
    soi2015_adj = SOI_sample_2015 * mult,
    puf2015_adj = PUF_2015 * mult
  )
skimr::skim_without_charts(compdata1)
compdata1 |> filter(adjust)

compdata <- compdata1 |> select(puf_name, description, soi2015_adj, pufsumk)

```

## Begin mapping PUF variables to IRS totals

Compare full-sample totals for PUF variables to IRS totals

```{r}
#| output: false

count(ptargets2, table, fname, table_description)
count(ptargets2, datatype)
count(ptargets2, subgroup)
count(ptargets2, targtype)

comptargets <- ptargets2 |>
  filter(
    year == 2015,
    datatype == "filers",
    subgroup == "all",
    targtype == "amount",
    incsort == 1
  )

comma_vars <- c("soi2015_adj", "ptarget", "diff", "pufsumk")
pct_vars <- c("pdiff")

```

### Round 1: EXACT MATCH

Start by finding exact matches between expected IRS totals (soi2015_adj) and actual IRS totals pulled from spreadsheets.

```{r}
#| label: round1-explore

# dtol <- 0.0
ptol <- 0.0
compare1 <- compdata |>
  mutate(lb = soi2015_adj * (1 - ptol), ub = soi2015_adj * (1 + ptol)) |>
  left_join(comptargets, join_by(lb <= ptarget, ub >= ptarget)) |>
  filter(!is.na(ptarget)) |>
  mutate(diff = ptarget - soi2015_adj, pdiff = diff / soi2015_adj) |>
  relocate(vname, .after = description) |>
  relocate(c(ptarget, diff, pdiff), .after = soi2015_adj) |>
  arrange(desc(soi2015_adj), desc(abs(diff)))

```

```{r}
#| label: show-round1
#| output: true

compare1 |>
  select(
    targetid,
    puf_name:pufsumk,
    table,
    datatype,
    subgroup,
    targtype,
    fname,
    xlcolumn,
    xlrownum
  ) |>
  gt() |>
  tab_header("Round 1 exact match results") |>
  fmt_number(columns = comma_vars, decimals = 0) |>
  fmt_percent(columns = pct_vars, decimals = 2)

```

Duplicate matches

```{r}
#| output: true

compare1 |>
  select(
    targetid,
    puf_name:pufsumk,
    table,
    datatype,
    subgroup,
    targtype,
    fname,
    xlcolumn,
    xlrownum
  ) |>
  mutate(n = n(), .by = puf_name) |>
  filter(n > 1) |>
  gt() |>
  tab_header(
    "Round 1 duplicates where puf variable has more than 1 exact matches"
  ) |>
  fmt_number(columns = comma_vars, decimals = 0) |>
  fmt_percent(columns = pct_vars, decimals = 2)

```

Get unique round1 results

```{r}

round1 <- compare1 |> filter(!targetid == 1)


```

### Round 2: Near-exact matches (expected amounts within 0.1% of IRS)

```{r}

ptol <- 0.001
compare2 <- compdata |>
  filter(!puf_name %in% round1$puf_name) |>
  mutate(lb = soi2015_adj * (1 - ptol), ub = soi2015_adj * (1 + ptol)) |>
  left_join(comptargets, join_by(lb <= ptarget, ub >= ptarget)) |>
  filter(!is.na(ptarget)) |>
  mutate(diff = ptarget - soi2015_adj, pdiff = diff / soi2015_adj) |>
  relocate(vname, .after = description) |>
  relocate(c(ptarget, diff, pdiff), .after = soi2015_adj) |>
  arrange(desc(soi2015_adj), desc(abs(diff)))

```


```{r}
#| label: show-round1
#| output: true

compare2 |>
  select(
    targetid,
    puf_name:pufsumk,
    table,
    datatype,
    subgroup,
    targtype,
    fname,
    xlcolumn,
    xlrownum
  ) |>
  gt() |>
  tab_header("Round 2 near-exact match results") |>
  fmt_number(columns = comma_vars, decimals = 0) |>
  fmt_percent(columns = pct_vars, decimals = 2)

```

There are 3 extremely close matches. The only one that appears valid is E01500 and pensions, which have the same basic name and are within \$1. The others are not matches.

```{r}

# it's obvious there are no dups
round2 <- compare2 |> filter(puf_name == "E01500")

```


### Round 3: Close matches (expected amounts within 1% of IRS)


```{r}

ptol <- 0.01
compare3 <- compdata |>
  filter(!puf_name %in% c(round1$puf_name, round2$puf_name)) |>
  mutate(lb = soi2015_adj * (1 - ptol), ub = soi2015_adj * (1 + ptol)) |>
  left_join(comptargets, join_by(lb <= ptarget, ub >= ptarget)) |>
  filter(!is.na(ptarget)) |>
  mutate(diff = ptarget - soi2015_adj, pdiff = diff / soi2015_adj) |>
  relocate(vname, .after = description) |>
  relocate(c(ptarget, diff, pdiff), .after = soi2015_adj) |>
  arrange(desc(soi2015_adj), desc(abs(diff)))

# which if any of these targets were NOT already used in round 1 or round 2

compare3a <- compare3 |>
  filter(!targetid %in% c(round1$targetid, round2$targetid))

```


Round 3 is a bust:

- Only 6 IRS targets were found that were not previously paired with an expected total
- Based on variable descriptions, NONE was a good match.

```{r}

amount_matches <- bind_rows(round1, round2)

amount_matches |>
  select(
    targetid,
    puf_name:pufsumk,
    table,
    datatype,
    subgroup,
    targtype,
    fname,
    xlcolumn,
    xlrownum
  ) |>
  gt() |>
  tab_header("Good matches for amount variables after 3 rounds") |>
  fmt_number(columns = comma_vars, decimals = 0) |>
  fmt_percent(columns = pct_vars, decimals = 2)

```
